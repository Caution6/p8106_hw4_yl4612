---
title: "Homework 4" 
author: "Yanhao Li"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


\newpage

```{r}
library(tidyverse)
library(ISLR)
library(lasso2)
library(ISLR)
library(rpart)
library(rpart.plot)
library(randomForest)
library(ranger)
library(caret)
library(gbm)
```

# Question 1

Load, clean, and tidy data

```{r}
data("Prostate")

prostate = Prostate %>% 
  janitor::clean_names()
```

### Question a

```{r}
set.seed(1)

tree1 = rpart(formula = lpsa ~ ., 
               data = prostate)

rpart.plot(tree1)

cpTable <- tree1$cptable

plotcp(tree1)

# minimum cross-validation error
minErr <- which.min(cpTable[,4])

tree2 <- prune(tree1, cp = cpTable[minErr,1])

rpart.plot(tree2)

# 1SE rule
tree3 <- prune(tree1, cp = cpTable[cpTable[,4] < cpTable[minErr,4] + cpTable[minErr,5],1][1])

rpart.plot(tree3)
```

Tree size corresponds to the lowest cross-validation error is 8. It is different from the tree size obtained using the 1 SE rule, which is 3. 

### Question b

```{r}
plotcp(tree1)

set.seed(1)

tree4 <- rpart(formula = lpsa ~ .,
               data = prostate,
               control = rpart.control(cp = 0.1))

rpart.plot(tree4)
```

A good choice of cp for pruning is often the leftmost value for which the mean lies below the horizontal line. According to the plot, I choose cp equals to 0.1 and size of tree equals to 3. 

In terminal node where lcvol is less than -0.48, the mean lpsa is 0.6. This node contains 9% of the sample.

### Question c

```{r}
ctrl <- trainControl(method = "cv")

bag.grid <- expand.grid(mtry = 8,
                       splitrule = "variance",
                       min.node.size = 1:30)

set.seed(1)

bag.fit <- train(lpsa~., 
                 Prostate, 
                 method = "ranger",
                 tuneGrid = bag.grid,
                 trControl = ctrl,
                 importance = "permutation")

ggplot(bag.fit, highlight = TRUE)

barplot(sort(ranger::importance(bag.fit$finalModel), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan","blue"))(19))
```

According to the plot, variable importance from highest to lowest is lcavol, lweight, svi, pgg45, lcp, gleason, lbph, and age. 

### Question d

```{r}
rf.grid <- expand.grid(mtry = 1:8,
                       splitrule = "variance",
                       min.node.size = 1:30)

set.seed(1)

rf.fit <- train(lpsa ~ . , 
                prostate, 
                method = "ranger",
                tuneGrid = rf.grid,
                trControl = ctrl,
                importance = "permutation")

ggplot(rf.fit, highlight = TRUE)

barplot(sort(ranger::importance(rf.fit$finalModel), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan","blue"))(19))
```

According to the plot, variable importance from highest to lowest is lcavol, lweight, svi, lcp, pgg45, lbph, gleason, and age. 

### Question e

```{r}
gbm.grid <- expand.grid(n.trees = c(2000,3000),
                        interaction.depth = 2:10,
                        shrinkage = c(0.001,0.003,0.005),
                        n.minobsinnode = 1)

set.seed(1)

gbm.fit <- train(lpsa ~ . , 
                 prostate, 
                 method = "gbm",
                 tuneGrid = gbm.grid,
                 trControl = ctrl,
                 verbose = FALSE)

ggplot(gbm.fit, highlight = TRUE)

summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```

According to the plot, variable importance from highest to lowest is lcavol, lweight, svi, pgg45, lcp, age, lbph, and gleason. 

### Question f

```{r}
resamp <- resamples(list(bag = bag.fit, rf = rf.fit, bst = gbm.fit))

summary(resamp)
```

According to the table, random forest has lower mean RMSE. Consequently, I will choose random forest.

# Question 2

Load, clean, and tidy data

```{r}
data("OJ")

oj <- OJ %>% 
  janitor::clean_names()

set.seed(1)

rowTrain = createDataPartition(y = oj$purchase,
                               p = 799/1070,
                               list = FALSE)
```

### Question a

```{r}
rpart.fit <- train(purchase~., 
                   oj, 
                   subset = rowTrain,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-6,-3, len = 20))),
                   trControl = ctrl)

ggplot(rpart.fit, highlight = TRUE)

rpart.plot(rpart.fit$finalModel)

rpart.pred <- predict(rpart.fit, newdata = oj[-rowTrain,])

mean(rpart.pred != oj$purchase[-rowTrain])
```

The test classification error rate is 17.4%.

### Question b

```{r}
rf.grid2 <- expand.grid(mtry = 1:10,
                       splitrule = "gini",
                       min.node.size = 1:6)

set.seed(1)

rf.fit2 <- train(purchase~., 
                oj, 
                subset = rowTrain,
                method = "ranger",
                tuneGrid = rf.grid2,
                trControl = ctrl,
                importance = "permutation")

ggplot(rf.fit2, highlight = TRUE)

barplot(sort(ranger::importance(rf.fit2$finalModel), decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan","blue"))(19))

rf.pred <- predict(rf.fit2, newdata = oj[-rowTrain,])

mean(rf.pred != oj$purchase[-rowTrain])
```

According to the plot, variable importance rank from highest to lowest.

The test classification error rate is 20%.

### Question c

```{r}
gbm.grid2 <- expand.grid(n.trees = c(2000,3000),
                        interaction.depth = 2:10,
                        shrinkage = c(0.001,0.003,0.005),
                        n.minobsinnode = 1)

set.seed(1)

gbm.fit2 <- train(purchase~., 
                 oj, 
                 subset = rowTrain, 
                 tuneGrid = gbm.grid2,
                 trControl = ctrl,
                 method = "gbm",
                 verbose = FALSE)

ggplot(gbm.fit2, highlight = TRUE)

summary(gbm.fit2$finalModel, las = 2, cBars = 19, cex.names = 0.6)

gbm.pred <- predict(gbm.fit2, newdata = oj[-rowTrain,])

mean(gbm.pred != oj$purchase[-rowTrain])
```

According to the plot, variable importance rank from highest to lowest.

The test classification error rate is 19.3%. 
